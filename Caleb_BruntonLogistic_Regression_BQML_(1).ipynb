{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CalebBrunton2/mgmt467-analytics-portfolio/blob/main/Caleb_BruntonLogistic_Regression_BQML_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIk5BPJs01W"
      },
      "source": [
        "# üé¨ Netflix Churn in BigQuery ML ‚Äî Colab Notebook\n",
        "\n",
        "This notebook walks you through a **step-by-step (9-cell) pipeline** to build a **features + label** table (`feat_churn_lite`) from `users` and `watch_history`, followed by a **minimal logistic regression** using **BigQuery ML**.\n",
        "\n",
        "We keep complexity at **Level 4**: basic joins, rolling features, and next-month churn labeling ‚Äî perfect for a warm-up before adding Gemini-assisted improvements."
      ],
      "id": "eCIk5BPJs01W"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Objectives\n",
        "Build confidence with SQL progressively (Levels 0‚Äì4): counts, grouping, date truncation, joins, and window functions.\n",
        "\n",
        "Construct a user√ómonth panel that includes zero-activity months and create rolling 3-month features (r3_sess, r3_min).\n",
        "Define a clean next-month churn label (inactive next month = 1) without data leakage.\n",
        "\n",
        "Orchestrate a reproducible Colab ‚Üí BigQuery workflow that materializes each step as a table.\n",
        "\n",
        "Train a minimal BigQuery ML logistic regression, evaluate it (AUC, log loss, ROC/PR, confusion matrix), and generate a scored table for the latest month.\n",
        "Practice model discipline: small feature set, clear assumptions, sanity checks, and an auditable pipeline.\n",
        "\n",
        "Use Gemini to synthesize a single-query CTE equivalent of your 9-step pipeline and verify equivalence.\n",
        "\n"
      ],
      "metadata": {
        "id": "3pWObVrKyXSu"
      },
      "id": "3pWObVrKyXSu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement\n",
        "You are the data analyst for a streaming platform with three core tables: users, watch_history, and (optionally later) movies. Product leadership wants an early warning signal for which users are likely to be inactive next month so lifecycle marketing can target preventive outreach. Your task is to build a transparent, baseline churn pipeline‚Äîstaying:\n",
        "* Creates a canonical calendar of months and a user√ómonth grid,\n",
        "* Aggregates watch behavior to monthly sessions and minutes, filling zero-activity months,\n",
        "* Engineers minimal, interpretable rolling features (r3_sess, r3_min),\n",
        "* Defines the label churn_next_month = 1 ‚àí active_next_month,\n",
        "* Trains and evaluates a logistic regression using only r3_sess, r3_min, subscription_plan, country, and age,\n",
        "* Produces ranked churn probabilities for the most recent month, and\n",
        "Uses Gemini to compress the pipeline into one CTE query and verify it matches your materialized table.\n",
        "\n",
        "\n",
        "## Constraints\n",
        "Use only past and present information to predict the next month (no peeking into the future).\n",
        "Keep features minimal and documented; label logic must be auditable.\n",
        "Deliverables:\n",
        "* A BigQuery table feat_churn_lite (features + label).\n",
        "* A trained model churn_logreg_lite with evaluation metrics.\n",
        "* A predictions table for the latest month with churn probabilities.\n",
        "* A Gemini-generated single-query CTE and an equivalence check showing parity with your pipeline.\n",
        "\n",
        "Baseline target: model performance meaningfully above random (e.g., AUC > 0.60) with clear notes on next steps to improve."
      ],
      "metadata": {
        "id": "N2ZLjUWoyr9k"
      },
      "id": "N2ZLjUWoyr9k"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGldg6nQs01W"
      },
      "source": [
        "## ‚¨úÔ∏è Cell 0 ‚Äî Setup\n",
        "\n",
        "- Authenticate to Google Cloud from Colab  \n",
        "- Initialize BigQuery client  \n",
        "- Set your **Project ID** and **Dataset** (edit these two variables)"
      ],
      "id": "UGldg6nQs01W"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "pFSYD78jtH6S"
      },
      "id": "pFSYD78jtH6S"
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 0: Connect to BigQuery\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.cloud import bigquery\n",
        "PROJECT_ID = \"original-wonder-471819-n2\"\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "print(\"‚úÖ Connected to BigQuery project:\", PROJECT_ID)\n"
      ],
      "metadata": {
        "id": "7vIhTBNrtGiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41887e7b-fc4d-4f3b-942f-5be56cc847f5"
      },
      "id": "7vIhTBNrtGiq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate"
      ],
      "metadata": {
        "id": "g25vY2kFtM_v"
      },
      "id": "g25vY2kFtM_v"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.86624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6644932f-58fe-4d1a-e860-c21f8a592283"
      },
      "source": [
        "%%bigquery --project original-wonder-471819-n2\n",
        "SELECT CURRENT_DATE() AS today, SESSION_USER() AS user;\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mgmt-467-47888 netflix us-central1\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "cell_1761199794.86624"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtOffJ54s01X"
      },
      "source": [
        "## ‚¨úÔ∏è Cell 1 ‚Äî Month Bounds\n",
        "\n",
        "Find the **minimum** and **maximum** months in `watch_history`.  \n",
        "We‚Äôll use these to generate a canonical calendar of months that covers the entire activity range."
      ],
      "id": "QtOffJ54s01X"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "bq = bigquery.Client(project=PROJECT_ID)"
      ],
      "metadata": {
        "id": "3V2M2mx2Lnzq"
      },
      "id": "3V2M2mx2Lnzq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.month_bounds` AS\n",
        "SELECT\n",
        "  DATE_TRUNC(MIN(DATE(watch_date)), MONTH) AS min_month,\n",
        "  DATE_TRUNC(MAX(DATE(watch_date)), MONTH) AS max_month\n",
        "FROM `{PROJECT_ID}.{DATASET}.watch_history`;\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì month_bounds\")"
      ],
      "metadata": {
        "id": "_J_LSwqr02cq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e7b267d3-fa9c-4ae7-b107-4908721fdf11"
      },
      "id": "_J_LSwqr02cq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Forbidden",
          "evalue": "403 POST https://bigquery.googleapis.com/bigquery/v2/projects/mgmt-467-47888/jobs?prettyPrint=false: Access Denied: Project mgmt-467-47888: User does not have bigquery.jobs.create permission in project mgmt-467-47888.\n\nLocation: None\nJob ID: 4cd35cb2-3b59-4168-b5e1-10089a0d0dc1\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3829308926.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mFROM\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_history\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úì month_bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[1;32m   3571\u001b[0m             )\n\u001b[1;32m   3572\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mapi_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0menums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryApiMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINSERT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3573\u001b[0;31m             return _job_helpers.query_jobs_insert(\n\u001b[0m\u001b[1;32m   3574\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3575\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_job_helpers.py\u001b[0m in \u001b[0;36mquery_jobs_insert\u001b[0;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, callback)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mdo_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DEFAULT_QUERY_JOB_INSERT_RETRY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# The future might be in a failed state now, but if it's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_job_helpers.py\u001b[0m in \u001b[0;36mdo_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mjob_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 callback(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAPICallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m             exc.message = _EXCEPTION_FOOTER_TEMPLATE.format(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/base.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;31m# job has an ID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mspan_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         api_response = client._call_api(\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mspan_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BigQuery.job.begin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             ):\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/mgmt-467-47888/jobs?prettyPrint=false: Access Denied: Project mgmt-467-47888: User does not have bigquery.jobs.create permission in project mgmt-467-47888.\n\nLocation: None\nJob ID: 4cd35cb2-3b59-4168-b5e1-10089a0d0dc1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check if the table is creatred"
      ],
      "metadata": {
        "id": "N26TRHbw2_sZ"
      },
      "id": "N26TRHbw2_sZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beb59cb2"
      },
      "source": [
        "sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{DATASET}.month_bounds`\n",
        "\"\"\"\n",
        "\n",
        "bq.query(sql).result().to_dataframe()"
      ],
      "id": "beb59cb2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZKWfTkas01X"
      },
      "source": [
        "## ‚¨úÔ∏è Cell 2 ‚Äî Calendar of Months\n",
        "\n",
        "Create a dense **month calendar** from `min_month` to `max_month`.  \n",
        "This ensures we consider **months with zero activity**, which are crucial for churn labeling."
      ],
      "id": "rZKWfTkas01X"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.866431"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.calendar_months` AS\n",
        "WITH bounds AS (\n",
        "  SELECT min_month, max_month FROM `{PROJECT_ID}.{DATASET}.month_bounds`\n",
        "),\n",
        "seq AS (\n",
        "  SELECT GENERATE_DATE_ARRAY(\n",
        "    (SELECT min_month FROM bounds),\n",
        "    (SELECT max_month FROM bounds),\n",
        "    INTERVAL 1 MONTH\n",
        "  ) AS months\n",
        ")\n",
        "SELECT month\n",
        "FROM seq, UNNEST(months) AS month;\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì calendar_months\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.866431"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check if the table was created"
      ],
      "metadata": {
        "id": "MDh7KVXY3VJk"
      },
      "id": "MDh7KVXY3VJk"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{DATASET}.calendar_months`\n",
        "ORDER BY month\n",
        "Limit 5\n",
        "\"\"\"\n",
        "\n",
        "bq.query(sql).result().to_dataframe()"
      ],
      "metadata": {
        "id": "1Vkir-WF3UAB"
      },
      "id": "1Vkir-WF3UAB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtmm5JVas01X"
      },
      "source": [
        "## ‚¨úÔ∏è Cell 3 ‚Äî User √ó Month Grid\n",
        "\n",
        "Build a canonical **user √ó month** grid so every user has a row for every month, even if they had **no sessions**."
      ],
      "id": "Mtmm5JVas01X"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.86653"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.user_month_grid` AS\n",
        "SELECT u.user_id, c.month\n",
        "FROM (SELECT DISTINCT user_id FROM `{PROJECT_ID}.{DATASET}.users`) u\n",
        "CROSS JOIN `{PROJECT_ID}.{DATASET}.calendar_months` c;\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì user_month_grid\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.86653"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{DATASET}.user_month_grid`\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "bq.query(sql).result().to_dataframe()"
      ],
      "metadata": {
        "id": "s8vTiWd731vD"
      },
      "id": "s8vTiWd731vD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_uIdTKWs01Y"
      },
      "source": [
        "## ‚¨úÔ∏è Cell 4 ‚Äî Monthly Activity Aggregation\n",
        "\n",
        "Aggregate `watch_history` to **monthly sessions** and **minutes** per user.  \n",
        "We do not use rolling sums yet; just raw monthly totals."
      ],
      "id": "s_uIdTKWs01Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.866619"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.activity_monthly` AS\n",
        "SELECT\n",
        "  user_id,\n",
        "  DATE_TRUNC(DATE(watch_date), MONTH) AS month,\n",
        "  COUNT(*) AS sessions,\n",
        "  SUM(watch_duration_minutes) AS minutes\n",
        "FROM `{PROJECT_ID}.{DATASET}.watch_history`\n",
        "GROUP BY 1,2;\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì activity_monthly\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.866619"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display 5 records"
      ],
      "metadata": {
        "id": "2rKsNEe04L9O"
      },
      "id": "2rKsNEe04L9O"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{DATASET}.activity_monthly`\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "bq.query(sql).result().to_dataframe()"
      ],
      "metadata": {
        "id": "Hz_2RRsN4D24"
      },
      "id": "Hz_2RRsN4D24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeGuBmeZs01Y"
      },
      "source": [
        "## ‚¨úÔ∏è Cell 5 ‚Äî Fill Zero-Activity Months\n",
        "\n",
        "Left-join the monthly activity onto the **user √ó month grid** and fill missing as zeros.  \n",
        "This step ensures **churn** (no activity next month) can be correctly labeled."
      ],
      "id": "EeGuBmeZs01Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.866705"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.activity_filled` AS\n",
        "SELECT\n",
        "  g.user_id,\n",
        "  g.month,\n",
        "  COALESCE(a.sessions, 0) AS sessions,\n",
        "  COALESCE(a.minutes, 0)  AS minutes\n",
        "FROM `{PROJECT_ID}.{DATASET}.user_month_grid` g\n",
        "LEFT JOIN `{PROJECT_ID}.{DATASET}.activity_monthly` a\n",
        "USING (user_id, month);\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì activity_filled\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.866705"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{DATASET}.activity_filled`\n",
        "WHERE sessions = 0 AND minutes = 0\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "bq.query(sql).result().to_dataframe()"
      ],
      "metadata": {
        "id": "1-zP7Q6O4Y2r"
      },
      "id": "1-zP7Q6O4Y2r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u47UVGys01Y"
      },
      "source": [
        "## ‚¨úÔ∏è Cell 6 ‚Äî Rolling 3-Month Features\n",
        "\n",
        "**Feature Engineering:** Compute **recency/frequency** (`r3_sess`) and **intensity** (`r3_min`) as rolling 3-month sums per user.  \n",
        "These are compact but strong baseline features for churn prediction."
      ],
      "id": "0u47UVGys01Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.86679"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.activity_roll3` AS\n",
        "SELECT\n",
        "  user_id,\n",
        "  month,\n",
        "  sessions,\n",
        "  minutes,\n",
        "  SUM(sessions) OVER (\n",
        "    PARTITION BY user_id ORDER BY month\n",
        "    ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "  ) AS r3_sess,\n",
        "  SUM(minutes) OVER (\n",
        "    PARTITION BY user_id ORDER BY month\n",
        "    ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "  ) AS r3_min\n",
        "FROM `{PROJECT_ID}.{DATASET}.activity_filled`;\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì activity_roll3\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.86679"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{DATASET}.activity_roll3`\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "bq.query(sql).result().to_dataframe()"
      ],
      "metadata": {
        "id": "EwQzHBAm4vYT"
      },
      "id": "EwQzHBAm4vYT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNQejn-ws01Y"
      },
      "source": [
        "## ‚¨úÔ∏è Cell 7 ‚Äî Label: Next-Month Churn\n",
        "\n",
        "Define **active next month** = 1 if a user has **any sessions** next month, else 0.  \n",
        "Our label **`churn_next_month` = 1 - active_next_month** (1 means churn)."
      ],
      "id": "HNQejn-ws01Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.866866"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.labels_next_month` AS\n",
        "SELECT\n",
        "  user_id,\n",
        "  month,\n",
        "  LEAD(CASE WHEN sessions > 0 THEN 1 ELSE 0 END)\n",
        "    OVER (PARTITION BY user_id ORDER BY month) AS active_next_month\n",
        "FROM `{PROJECT_ID}.{DATASET}.activity_filled`;\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì labels_next_month\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.866866"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{DATASET}.labels_next_month`\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "bq.query(sql).result().to_dataframe()"
      ],
      "metadata": {
        "id": "EQ3twKft5H0o"
      },
      "id": "EQ3twKft5H0o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwpdAm5ts01Y"
      },
      "source": [
        "## ‚¨úÔ∏è Cell 8 ‚Äî User Attributes (Lite)\n",
        "\n",
        "Bring in simple demographic/product context: `subscription_plan`, `country`, `age`.  \n",
        "These keep the feature set small and interpretable."
      ],
      "id": "AwpdAm5ts01Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.866949"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.user_attrs_lite` AS\n",
        "SELECT user_id, subscription_plan, country, age\n",
        "FROM `{PROJECT_ID}.{DATASET}.users`;\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì user_attrs_lite\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.866949"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{DATASET}.user_attrs_lite`\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "bq.query(sql).result().to_dataframe()"
      ],
      "metadata": {
        "id": "JfEVjSwJ51e3"
      },
      "id": "JfEVjSwJ51e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqg-lW1ds01Y"
      },
      "source": [
        "## ‚¨úÔ∏è Cell 9 ‚Äî Assemble Final Feature + Label Table\n",
        "\n",
        "Join rolling features + user attributes + labels to build `feat_churn_lite`.  \n",
        "We drop rows where the label is `NULL` (i.e., there is no ‚Äúnext month‚Äù to label)."
      ],
      "id": "Bqg-lW1ds01Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.867037"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.feat_churn_lite` AS\n",
        "SELECT\n",
        "  r.user_id,\n",
        "  r.month,\n",
        "  r.r3_sess,\n",
        "  r.r3_min,\n",
        "  u.subscription_plan,\n",
        "  u.country,\n",
        "  u.age,\n",
        "  CASE\n",
        "    WHEN l.active_next_month = 1 THEN 0\n",
        "    WHEN l.active_next_month = 0 THEN 1\n",
        "    ELSE NULL\n",
        "  END AS churn_next_month\n",
        "FROM `{PROJECT_ID}.{DATASET}.activity_roll3` r\n",
        "JOIN `{PROJECT_ID}.{DATASET}.user_attrs_lite` u USING (user_id)\n",
        "JOIN `{PROJECT_ID}.{DATASET}.labels_next_month` l USING (user_id, month)\n",
        "WHERE l.active_next_month IS NOT NULL;\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì feat_churn_lite\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.867037"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "bq.query(sql).result().to_dataframe()"
      ],
      "metadata": {
        "id": "lTBPYgoK6B5N"
      },
      "id": "lTBPYgoK6B5N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksFmiVoMs01Z"
      },
      "source": [
        "## ‚úÖ Quick Sanity Checks (Optional)\n",
        "\n",
        "Confirm the label is present, inspect class balance, and ensure features are populated."
      ],
      "id": "ksFmiVoMs01Z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.867123"
      },
      "source": [
        "checks = f\"\"\"\n",
        "SELECT 'rows_total' AS check_name, COUNT(*) AS val FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`\n",
        "UNION ALL\n",
        "SELECT 'null_labels', COUNTIF(churn_next_month IS NULL) FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`\n",
        "UNION ALL\n",
        "SELECT 'class_0', COUNT(*) FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite` WHERE churn_next_month=0\n",
        "UNION ALL\n",
        "SELECT 'class_1', COUNT(*) FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite` WHERE churn_next_month=1;\n",
        "\"\"\"\n",
        "from pandas import set_option\n",
        "set_option('display.max_rows', 10)\n",
        "bq.query(checks).result().to_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.867123"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxu2AZw7s01Z"
      },
      "source": [
        "# üîÆ Logistic Regression (BigQuery ML)\n",
        "\n",
        "We now train a **minimal logistic regression** using the features we built, evaluate it, and generate predictions for the last month."
      ],
      "id": "Wxu2AZw7s01Z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVLtgldCs01Z"
      },
      "source": [
        "## ‚¨úÔ∏è Train ‚Äî Minimal Model (AUTO Split)\n",
        "\n",
        "Uses: `r3_sess`, `r3_min`, `subscription_plan`, `country`, `age`  \n",
        "Label: `churn_next_month`"
      ],
      "id": "xVLtgldCs01Z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a9f3b54"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`\n",
        "OPTIONS (\n",
        "  model_type = 'logistic_reg',\n",
        "  input_label_cols = ['churn_next_month'],\n",
        "  data_split_method = 'SEQ',\n",
        "  data_split_col = 'month' -- Use the 'month' column for sequential splitting\n",
        ") AS\n",
        "SELECT\n",
        "  churn_next_month,\n",
        "  r3_sess, r3_min,\n",
        "  subscription_plan, country, age,\n",
        "  month -- Include month in the select list for SEQ split\n",
        "FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`\n",
        "ORDER BY month; -- Order by month for sequential split\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì trained model:\", f\"{PROJECT_ID}.{DATASET}.churn_logreg_lite\")"
      ],
      "id": "6a9f3b54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTyPDRyks01Z"
      },
      "source": [
        "## ‚¨úÔ∏è Evaluate ‚Äî Metrics & Curves\n",
        "\n",
        "We‚Äôll look at AUC and log_loss, plus fetch ROC/PR curve points.  \n",
        "Students can plot these in later exercises if desired."
      ],
      "id": "wTyPDRyks01Z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.86732"
      },
      "source": [
        "eval_df = bq.query(\n",
        "    f\"SELECT * FROM ML.EVALUATE(MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`);\"\n",
        ").result().to_dataframe()\n",
        "eval_df"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.86732"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.86736"
      },
      "source": [
        "roc_df = bq.query(\n",
        "    f\"SELECT * FROM ML.ROC_CURVE(MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`);\"\n",
        ").result().to_dataframe()\n",
        "roc_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.86736"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.8674"
      },
      "source": [
        "f\"\"\"\n",
        "SELECT * FROM ML.PR_CURVE(MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`)\n",
        "\"\"\"\n",
        "pr_df = bq.query(sql).result().to_dataframe()\n",
        "pr_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.8674"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761199794.867441"
      },
      "source": [
        "cm_df = bq.query(f\"\"\"\n",
        "SELECT *\n",
        "FROM ML.CONFUSION_MATRIX(\n",
        "  MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`,\n",
        "  (SELECT\n",
        "     churn_next_month,\n",
        "     r3_sess, r3_min, subscription_plan, country, age\n",
        "   FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`),\n",
        "  STRUCT(0.5 AS threshold)\n",
        ");\n",
        "\"\"\").result().to_dataframe()\n",
        "cm_df"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cell_1761199794.867441"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5Qxvdtqs01Z"
      },
      "source": [
        "## ‚¨úÔ∏è Predict ‚Äî Score the Latest Month\n",
        "\n",
        "We score the most recent month in `feat_churn_lite` and save predictions to a table for inspection or dashboards."
      ],
      "id": "G5Qxvdtqs01Z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5396c399"
      },
      "source": [
        "# Helper: last month to score\n",
        "bq.query(f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.score_month` AS\n",
        "SELECT MAX(month) AS score_month\n",
        "FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`;\n",
        "\"\"\").result()\n",
        "\n",
        "# Predictions table\n",
        "bq.query(f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.churn_predictions_lite` AS\n",
        "WITH to_score AS (\n",
        "  SELECT f.*\n",
        "  FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite` f\n",
        "  CROSS JOIN `{PROJECT_ID}.{DATASET}.score_month` s\n",
        "  WHERE f.month = s.score_month\n",
        ")\n",
        "SELECT\n",
        "  user_id,\n",
        "  month AS score_month,\n",
        "  predicted_churn_next_month AS yhat,\n",
        "  (SELECT prob FROM UNNEST(predicted_churn_next_month_probs) WHERE label = predicted_churn_next_month) AS prob_churn\n",
        "FROM ML.PREDICT(\n",
        "  MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`,\n",
        "  TABLE to_score\n",
        ");\n",
        "\"\"\").result()\n",
        "\n",
        "bq.query(\n",
        "    f\"SELECT * FROM `{PROJECT_ID}.{DATASET}.churn_predictions_lite` ORDER BY prob_churn DESC LIMIT 20\"\n",
        ").result().to_dataframe()"
      ],
      "id": "5396c399",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "* Analyze current features\n",
        "* Brainstorm new features\n",
        "* Feature engineering\n",
        "* Iterate on the model\n",
        "* Evaluate the improved model\n",
        "* Refine features and model\n",
        "* Finish task"
      ],
      "metadata": {
        "id": "g2wZAOrM0sBe"
      },
      "id": "g2wZAOrM0sBe"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Hnq4apD0kSa"
      },
      "id": "0Hnq4apD0kSa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJVcqqQNs01Z"
      },
      "source": [
        "---\n",
        "\n",
        "## ü§ñ Gemini Synthesis & Compare Prompt\n",
        "\n",
        "Use this prompt with Gemini (in the side panel or a text cell) to generate a **single-query CTE** version of your 9-step pipeline and then **compare results** against your materialized table.\n",
        "\n",
        "**Copy/paste this prompt:**"
      ],
      "id": "NJVcqqQNs01Z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpaF_1HOs01Z"
      },
      "source": [
        "```\n",
        "You are a data engineering copilot. I built a 9-step BigQuery pipeline that creates `${PROJECT_ID}.${DATASET}.feat_churn_lite` with features (r3_sess, r3_min, subscription_plan, country, age) and label churn_next_month, using:\n",
        "1) month_bounds\n",
        "2) calendar_months\n",
        "3) user_month_grid\n",
        "4) activity_monthly\n",
        "5) activity_filled\n",
        "6) activity_roll3\n",
        "7) labels_next_month\n",
        "8) user_attrs_lite\n",
        "9) final select\n",
        "\n",
        "Task A: Produce a single BigQuery SQL (CTEs only; no CREATE TABLE) that computes the same final columns directly from `${PROJECT_ID}.${DATASET}.users` and `${PROJECT_ID}.${DATASET}.watch_history` with identical logic: calendar, user√ómonth grid, zero fill, rolling 3-month sums, and label from next-month activity.\n",
        "\n",
        "Task B: Produce a second SQL snippet that checks equivalence vs the materialized table:\n",
        "- Row count difference\n",
        "- Class distribution difference\n",
        "- A checksum hash over ordered (user_id, month)\n",
        "\n",
        "Return only two code blocks titled:\n",
        "-- SINGLE-QUERY CTE VERSION\n",
        "-- EQUIVALENCE CHECKS\n",
        "Use fully qualified names with my PROJECT_ID and DATASET placeholders.\n",
        "```"
      ],
      "id": "tpaF_1HOs01Z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeb0e6c0"
      },
      "source": [
        "sql = f\"\"\"\n",
        "-- SINGLE-QUERY CTE VERSION\n",
        "WITH month_bounds AS (\n",
        "  SELECT\n",
        "    DATE_TRUNC(MIN(DATE(watch_date)), MONTH) AS min_month,\n",
        "    DATE_TRUNC(MAX(DATE(watch_date)), MONTH) AS max_month\n",
        "  FROM `{PROJECT_ID}.{DATASET}.watch_history`\n",
        "),\n",
        "calendar_months AS (\n",
        "  SELECT month\n",
        "  FROM month_bounds,\n",
        "       UNNEST(GENERATE_DATE_ARRAY(min_month, max_month, INTERVAL 1 MONTH)) AS month\n",
        "),\n",
        "user_month_grid AS (\n",
        "  SELECT u.user_id, c.month\n",
        "  FROM (SELECT DISTINCT user_id FROM `{PROJECT_ID}.{DATASET}.users`) u\n",
        "  CROSS JOIN calendar_months c\n",
        "),\n",
        "activity_monthly AS (\n",
        "  SELECT\n",
        "    user_id,\n",
        "    DATE_TRUNC(DATE(watch_date), MONTH) AS month,\n",
        "    COUNT(*) AS sessions,\n",
        "    SUM(watch_duration_minutes) AS minutes\n",
        "  FROM `{PROJECT_ID}.{DATASET}.watch_history`\n",
        "  GROUP BY 1, 2\n",
        "),\n",
        "activity_filled AS (\n",
        "  SELECT\n",
        "    g.user_id,\n",
        "    g.month,\n",
        "    COALESCE(a.sessions, 0) AS sessions,\n",
        "    COALESCE(a.minutes, 0)  AS minutes\n",
        "  FROM user_month_grid g\n",
        "  LEFT JOIN activity_monthly a USING (user_id, month)\n",
        "),\n",
        "activity_roll3 AS (\n",
        "  SELECT\n",
        "    user_id,\n",
        "    month,\n",
        "    sessions,\n",
        "    minutes,\n",
        "    SUM(sessions) OVER (\n",
        "      PARTITION BY user_id ORDER BY month\n",
        "      ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "    ) AS r3_sess,\n",
        "    SUM(minutes) OVER (\n",
        "      PARTITION BY user_id ORDER BY month\n",
        "      ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "    ) AS r3_min\n",
        "  FROM activity_filled\n",
        "),\n",
        "labels_next_month AS (\n",
        "  SELECT\n",
        "    user_id,\n",
        "    month,\n",
        "    LEAD(CASE WHEN sessions > 0 THEN 1 ELSE 0 END)\n",
        "      OVER (PARTITION BY user_id ORDER BY month) AS active_next_month\n",
        "    FROM activity_filled\n",
        "),\n",
        "user_attrs_lite AS (\n",
        "  SELECT user_id, subscription_plan, country, age\n",
        "  FROM `{PROJECT_ID}.{DATASET}.users`\n",
        ")\n",
        "SELECT\n",
        "  r.user_id,\n",
        "  r.month,\n",
        "  r.r3_sess,\n",
        "  r.r3_min,\n",
        "  u.subscription_plan,\n",
        "  u.country,\n",
        "  u.age,\n",
        "  CASE\n",
        "    WHEN l.active_next_month = 1 THEN 0\n",
        "    WHEN l.active_next_month = 0 THEN 1\n",
        "    ELSE NULL\n",
        "  END AS churn_next_month\n",
        "FROM activity_roll3 r\n",
        "JOIN user_attrs_lite u USING (user_id)\n",
        "JOIN labels_next_month l USING (user_id, month)\n",
        "WHERE l.active_next_month IS NOT NULL;\n",
        "\"\"\"\n",
        "bq.query(sql).result().to_dataframe() # Execute and display results"
      ],
      "id": "eeb0e6c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3221f95"
      },
      "source": [
        "sql = f\"\"\"\n",
        "-- EQUIVALENCE CHECKS\n",
        "WITH cte_version AS (\n",
        "  -- Paste the SINGLE-QUERY CTE VERSION here\n",
        "  WITH month_bounds AS (\n",
        "    SELECT\n",
        "      DATE_TRUNC(MIN(DATE(watch_date)), MONTH) AS min_month,\n",
        "      DATE_TRUNC(MAX(DATE(watch_date)), MONTH) AS max_month\n",
        "    FROM `{PROJECT_ID}.{DATASET}.watch_history`\n",
        "  ),\n",
        "  calendar_months AS (\n",
        "    SELECT month\n",
        "    FROM month_bounds,\n",
        "         UNNEST(GENERATE_DATE_ARRAY(min_month, max_month, INTERVAL 1 MONTH)) AS month\n",
        "  ),\n",
        "  user_month_grid AS (\n",
        "    SELECT u.user_id, c.month\n",
        "    FROM (SELECT DISTINCT user_id FROM `{PROJECT_ID}.{DATASET}.users`) u\n",
        "    CROSS JOIN calendar_months c\n",
        "  ),\n",
        "  activity_monthly AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      DATE_TRUNC(DATE(watch_date), MONTH) AS month,\n",
        "      COUNT(*) AS sessions,\n",
        "      SUM(watch_duration_minutes) AS minutes\n",
        "    FROM `{PROJECT_ID}.{DATASET}.watch_history`\n",
        "    GROUP BY 1, 2\n",
        "  ),\n",
        "  activity_filled AS (\n",
        "    SELECT\n",
        "      g.user_id,\n",
        "      g.month,\n",
        "      COALESCE(a.sessions, 0) AS sessions,\n",
        "      COALESCE(a.minutes, 0)  AS minutes\n",
        "    FROM user_month_grid g\n",
        "    LEFT JOIN activity_monthly a USING (user_id, month)\n",
        "  ),\n",
        "  activity_roll3 AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      month,\n",
        "      sessions,\n",
        "      minutes,\n",
        "      SUM(sessions) OVER (\n",
        "        PARTITION BY user_id ORDER BY month\n",
        "        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "      ) AS r3_sess,\n",
        "      SUM(minutes) OVER (\n",
        "        PARTITION BY user_id ORDER BY month\n",
        "        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "      ) AS r3_min\n",
        "    FROM activity_filled\n",
        "  ),\n",
        "  labels_next_month AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      month,\n",
        "      LEAD(CASE WHEN sessions > 0 THEN 1 ELSE 0 END)\n",
        "        OVER (PARTITION BY user_id ORDER BY month) AS active_next_month\n",
        "    FROM activity_filled\n",
        "  ),\n",
        "  user_attrs_lite AS (\n",
        "    SELECT user_id, subscription_plan, country, age\n",
        "    FROM `{PROJECT_ID}.{DATASET}.users`\n",
        "  )\n",
        "  SELECT\n",
        "    r.user_id,\n",
        "    r.month,\n",
        "    r.r3_sess,\n",
        "    r.r3_min,\n",
        "    u.subscription_plan,\n",
        "    u.country,\n",
        "    u.age,\n",
        "    CASE\n",
        "      WHEN l.active_next_month = 1 THEN 0\n",
        "      WHEN l.active_next_month = 0 THEN 1\n",
        "      ELSE NULL\n",
        "    END AS churn_next_month\n",
        "  FROM activity_roll3 r\n",
        "  JOIN user_attrs_lite u USING (user_id)\n",
        "  JOIN labels_next_month l USING (user_id, month)\n",
        "  WHERE l.active_next_month IS NOT NULL\n",
        "),\n",
        "materialized_table AS (\n",
        "  SELECT user_id, month, r3_sess, r3_min, subscription_plan, country, age, churn_next_month\n",
        "  FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`\n",
        ")\n",
        "-- Equivalence Checks\n",
        "SELECT\n",
        "  'Row Count Difference' as check_name,\n",
        "  (SELECT COUNT(*) FROM cte_version) - (SELECT COUNT(*) FROM materialized_table) as value\n",
        "UNION ALL\n",
        "SELECT\n",
        "  'Class 0 Difference',\n",
        "  (SELECT COUNT(*) FROM cte_version WHERE churn_next_month = 0) - (SELECT COUNT(*) FROM materialized_table WHERE churn_next_month = 0)\n",
        "UNION ALL\n",
        "SELECT\n",
        "  'Class 1 Difference',\n",
        "  (SELECT COUNT(*) FROM cte_version WHERE churn_next_month = 1) - (SELECT COUNT(*) FROM materialized_table WHERE churn_next_month = 1)\n",
        "UNION ALL\n",
        "SELECT\n",
        "  'Checksum Hash Match (0=Match)',\n",
        "  IF(\n",
        "    (SELECT FARM_FINGERPRINT(STRING_AGG(TO_JSON_STRING(t) ORDER BY user_id, month)) FROM cte_version t) =\n",
        "    (SELECT FARM_FINGERPRINT(STRING_AGG(TO_JSON_STRING(t) ORDER BY user_id, month)) FROM materialized_table t),\n",
        "    0,\n",
        "    1\n",
        "  )\n",
        "\"\"\"\n",
        "bq.query(sql).result().to_dataframe() # Execute and display results"
      ],
      "id": "c3221f95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "* **Analyze current features:** Examine the existing features (r3_sess, r3_min, subscription_plan, country, age) to understand their contribution to the model and identify potential limitations.\n",
        "* **Brainstorm new features:** Based on the domain knowledge of streaming services and churn behavior, brainstorm new features that could capture user engagement, content preferences, or other relevant factors. Consider features derived from the watch_history and users tables.\n",
        "* **Feature engineering:** Create new features based on the brainstorming session. This might involve aggregating data, creating ratios, or extracting information from timestamps or other fields.\n",
        "* **Iterate on the model:** Add the new features to the feat_churn_lite table and retrain the BigQuery ML model.\n",
        "* **Evaluate the new model:** Evaluate the new model's performance using the same metrics as before (AUC, log loss, etc.) and compare it to the baseline model."
      ],
      "metadata": {
        "id": "sJK5v7ns7SNX"
      },
      "id": "sJK5v7ns7SNX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35e24464"
      },
      "source": [
        "# Task\n",
        "Analyze the current features in the `feat_churn_lite` table, brainstorm new features from the `watch_history` and `users` tables to improve the churn prediction model, engineer these new features, and outline a plan to iterate on the model with the new features and evaluate its performance."
      ],
      "id": "35e24464"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59b94a19"
      },
      "source": [
        "## Analyze current features\n",
        "\n",
        "### Subtask:\n",
        "Examine the existing features (`r3_sess`, `r3_min`, `subscription_plan`, `country`, `age`) to understand their contribution to the model and identify potential limitations.\n"
      ],
      "id": "59b94a19"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6cae17f"
      },
      "source": [
        "**Reasoning**:\n",
        "Review the model evaluation metrics and confusion matrix to understand the current model's performance and the contribution of existing features.\n",
        "\n"
      ],
      "id": "d6cae17f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "512m9dyi0c6h"
      },
      "source": [
        "cm_df = bq.query(f\"\"\"\n",
        "SELECT *\n",
        "FROM ML.CONFUSION_MATRIX(\n",
        "  MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`,\n",
        "  (SELECT\n",
        "     churn_next_month,\n",
        "     r3_sess, r3_min, subscription_plan, country, age\n",
        "   FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`),\n",
        "  STRUCT(0.5 AS threshold)\n",
        ");\n",
        "\"\"\").result().to_dataframe()\n",
        "\n",
        "print(\"Model Evaluation Metrics:\")\n",
        "display(eval_df)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Threshold = 0.5):\")\n",
        "display(cm_df)"
      ],
      "id": "512m9dyi0c6h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7b85aca"
      },
      "source": [
        "## Brainstorm new features\n",
        "\n",
        "### Subtask:\n",
        "Based on the domain knowledge of streaming services and churn behavior, brainstorm new features that could capture user engagement, content preferences, or other relevant factors. Consider features derived from the the `watch_history` and `users` tables.\n"
      ],
      "id": "d7b85aca"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c75dc356"
      },
      "source": [
        "**Reasoning**:\n",
        "Brainstorm new features based on domain knowledge and available data.\n",
        "\n"
      ],
      "id": "c75dc356"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "301c43db"
      },
      "source": [
        "# Brainstorming new features from watch_history and users tables\n",
        "\n",
        "print(\"Potential New Features for Churn Prediction:\")\n",
        "print(\"\\nEngagement-Related Features (from watch_history):\")\n",
        "print(\"- Monthly average watch duration: Captures typical viewing time per month. (Derived from watch_duration_minutes)\")\n",
        "print(\"- Number of unique days watched per month: Indicates regularity of engagement. (Derived from watch_date)\")\n",
        "print(\"- Longest continuous watching streak (in days) per month: Measures intense periods of engagement. (Derived from watch_date)\")\n",
        "print(\"- Proportion of content watched to completion (if content duration is available): Indicates content satisfaction. (Requires content duration data, not currently available)\")\n",
        "print(\"- Time since last watch: Recency of activity is a strong churn indicator. (Derived from watch_date)\")\n",
        "print(\"- Frequency of watching (e.g., average days between watches): Another measure of engagement regularity. (Derived from watch_date)\")\n",
        "print(\"- Number of different genres/categories watched per month: Measures content exploration/diversity. (Requires content genre/category data, not currently available)\")\n",
        "\n",
        "print(\"\\nContent-Related Features (from watch_history, potentially users for preferences):\")\n",
        "print(\"- Preferred genre/category (based on watch history): Users might churn if new content in their preferred area is lacking. (Requires content genre/category data)\")\n",
        "print(\"- Proportion of watching time spent on new releases: Indicates engagement with fresh content. (Requires content release date data)\")\n",
        "print(\"- Engagement with specific popular titles/franchises: High engagement might indicate loyalty. (Requires content title/franchise data)\")\n",
        "\n",
        "print(\"\\nUser-Related Features (from users, potentially combined with watch_history):\")\n",
        "print(\"- Tenure (months since joining): Longer tenure might indicate loyalty, but also potential for stagnation. (Derived from user join date, not currently available)\")\n",
        "print(\"- Number of devices used: Might indicate shared accounts or diverse viewing habits. (Requires device information, not currently available)\")\n",
        "print(\"- Customer support interactions (frequency, type): High frequency or certain types of interactions might precede churn. (Requires customer support data, not currently available)\")\n",
        "print(\"- Payment method/billing issues: Payment problems can lead to involuntary churn. (Requires billing data, not currently available)\")"
      ],
      "id": "301c43db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86a50b8e"
      },
      "source": [
        "## Feature engineering\n",
        "\n",
        "### Subtask:\n",
        "Create new features based on the brainstorming session. This might involve aggregating data, creating ratios, or extracting information from timestamps or other fields.\n"
      ],
      "id": "86a50b8e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "966afb4a"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the BigQuery SQL query to include new features derived from watch_history and users tables, specifically monthly average watch duration, number of unique days watched per month, and time since last watch. Then, execute the query to create or replace the feat_churn_lite table and verify the new columns.\n",
        "\n"
      ],
      "id": "966afb4a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um9tnSAP06hi"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.feat_churn_lite` AS\n",
        "WITH month_bounds AS (\n",
        "  SELECT\n",
        "    DATE_TRUNC(MIN(DATE(watch_date)), MONTH) AS min_month,\n",
        "    DATE_TRUNC(MAX(DATE(watch_date)), MONTH) AS max_month\n",
        "  FROM `{PROJECT_ID}.{DATASET}.watch_history`\n",
        "),\n",
        "calendar_months AS (\n",
        "  SELECT month\n",
        "  FROM month_bounds,\n",
        "       UNNEST(GENERATE_DATE_ARRAY(min_month, max_month, INTERVAL 1 MONTH)) AS month\n",
        "),\n",
        "user_month_grid AS (\n",
        "  SELECT u.user_id, c.month\n",
        "  FROM (SELECT DISTINCT user_id FROM `{PROJECT_ID}.{DATASET}.users`) u\n",
        "  CROSS JOIN calendar_months c\n",
        "),\n",
        "activity_monthly AS (\n",
        "  SELECT\n",
        "    user_id,\n",
        "    DATE_TRUNC(DATE(watch_date), MONTH) AS month,\n",
        "    COUNT(*) AS sessions,\n",
        "    SUM(watch_duration_minutes) AS minutes,\n",
        "    COUNT(DISTINCT DATE(watch_date)) AS unique_days_watched, -- New feature: unique days watched\n",
        "    AVG(watch_duration_minutes) AS avg_watch_duration -- New feature: average watch duration\n",
        "  FROM `{PROJECT_ID}.{DATASET}.watch_history`\n",
        "  GROUP BY 1, 2\n",
        "),\n",
        "activity_filled AS (\n",
        "  SELECT\n",
        "    g.user_id,\n",
        "    g.month,\n",
        "    COALESCE(a.sessions, 0) AS sessions,\n",
        "    COALESCE(a.minutes, 0)  AS minutes,\n",
        "    COALESCE(a.unique_days_watched, 0) AS unique_days_watched, -- New feature\n",
        "    COALESCE(a.avg_watch_duration, 0) AS avg_watch_duration -- New feature\n",
        "  FROM user_month_grid g\n",
        "  LEFT JOIN activity_monthly a USING (user_id, month)\n",
        "),\n",
        "activity_roll3 AS (\n",
        "  SELECT\n",
        "    user_id,\n",
        "    month,\n",
        "    sessions,\n",
        "    minutes,\n",
        "    unique_days_watched, -- Include new feature\n",
        "    avg_watch_duration, -- Include new feature\n",
        "    -- Calculate days since last watch based on the current month and the previous month\n",
        "    DATE_DIFF(month, LAG(month, 1, '1900-01-01') OVER (PARTITION BY user_id ORDER BY month), DAY) AS days_since_last_month_start, -- Days since the start of the previous month\n",
        "    SUM(sessions) OVER (\n",
        "      PARTITION BY user_id ORDER BY month\n",
        "      ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "    ) AS r3_sess,\n",
        "    SUM(minutes) OVER (\n",
        "      PARTITION BY user_id ORDER BY month\n",
        "      ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "    ) AS r3_min\n",
        "  FROM activity_filled\n",
        "),\n",
        "labels_next_month AS (\n",
        "  SELECT\n",
        "    user_id,\n",
        "    month,\n",
        "    LEAD(CASE WHEN sessions > 0 THEN 1 ELSE 0 END)\n",
        "      OVER (PARTITION BY user_id ORDER BY month) AS active_next_month\n",
        "    FROM activity_filled\n",
        "),\n",
        "user_attrs_lite AS (\n",
        "  SELECT user_id, subscription_plan, country, age\n",
        "  FROM `{PROJECT_ID}.{DATASET}.users`\n",
        ")\n",
        "SELECT\n",
        "  r.user_id,\n",
        "  r.month,\n",
        "  r.r3_sess,\n",
        "  r.r3_min,\n",
        "  r.unique_days_watched, -- Include new feature\n",
        "  r.avg_watch_duration, -- Include new feature\n",
        "  r.days_since_last_month_start, -- Include new feature\n",
        "  u.subscription_plan,\n",
        "  u.country,\n",
        "  u.age,\n",
        "  CASE\n",
        "    WHEN l.active_next_month = 1 THEN 0\n",
        "    WHEN l.active_next_month = 0 THEN 1\n",
        "    ELSE NULL\n",
        "  END AS churn_next_month\n",
        "FROM activity_roll3 r\n",
        "JOIN user_attrs_lite u USING (user_id)\n",
        "JOIN labels_next_month l USING (user_id, month)\n",
        "WHERE l.active_next_month IS NOT NULL;\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì feat_churn_lite with new features\")\n",
        "\n",
        "sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "bq.query(sql).result().to_dataframe()"
      ],
      "id": "Um9tnSAP06hi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d5fe09e"
      },
      "source": [
        "## Iterate on the model\n",
        "\n",
        "### Subtask:\n",
        "Retrain the BigQuery ML logistic regression model with the updated `feat_churn_lite` table containing the new features.\n"
      ],
      "id": "5d5fe09e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52860068"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct and execute the SQL query to retrain the BigQuery ML logistic regression model with the updated feat_churn_lite table, including the new features, and print a confirmation message.\n",
        "\n"
      ],
      "id": "52860068"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a08f492"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`\n",
        "OPTIONS (\n",
        "  model_type = 'logistic_reg',\n",
        "  input_label_cols = ['churn_next_month'],\n",
        "  data_split_method = 'SEQ',\n",
        "  data_split_col = 'month'\n",
        ") AS\n",
        "SELECT\n",
        "  churn_next_month,\n",
        "  r3_sess,\n",
        "  r3_min,\n",
        "  unique_days_watched,  -- Include new feature\n",
        "  avg_watch_duration,   -- Include new feature\n",
        "  days_since_last_month_start, -- Include new feature\n",
        "  subscription_plan,\n",
        "  country,\n",
        "  age,\n",
        "  month -- Include month for SEQ split\n",
        "FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`\n",
        "ORDER BY month; -- Order by month for sequential split\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì trained model:\", f\"{PROJECT_ID}.{DATASET}.churn_logreg_lite with new features\")"
      ],
      "id": "4a08f492",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2f1f16"
      },
      "source": [
        "## Evaluate the improved model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the retrained BigQuery ML model with the new features and compare it to the baseline model.\n"
      ],
      "id": "be2f1f16"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12363faa"
      },
      "source": [
        "**Reasoning**:\n",
        "Query the evaluation metrics, ROC curve data, PR curve data, and confusion matrix for the retrained model using ML.EVALUATE, ML.ROC_CURVE, ML.PR_CURVE, and ML.CONFUSION_MATRIX respectively, and then display the evaluation metrics and confusion matrix dataframes to assess the performance.\n",
        "\n"
      ],
      "id": "12363faa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnHAtR6o1e8c"
      },
      "source": [
        "eval_df_retrained = bq.query(\n",
        "    f\"SELECT * FROM ML.EVALUATE(MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`);\"\n",
        ").result().to_dataframe()\n",
        "\n",
        "roc_df_retrained = bq.query(\n",
        "    f\"SELECT * FROM ML.ROC_CURVE(MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`);\"\n",
        ").result().to_dataframe()\n",
        "\n",
        "cm_df_retrained = bq.query(f\"\"\"\n",
        "SELECT *\n",
        "FROM ML.CONFUSION_MATRIX(\n",
        "  MODEL `{PROJECT_ID}.{DATASET}.churn_logreg_lite`,\n",
        "  (SELECT\n",
        "     churn_next_month,\n",
        "     r3_sess, r3_min, unique_days_watched, avg_watch_duration, days_since_last_month_start,\n",
        "     subscription_plan, country, age\n",
        "   FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`),\n",
        "  STRUCT(0.5 AS threshold)\n",
        ");\n",
        "\"\"\").result().to_dataframe()\n",
        "\n",
        "print(\"Retrained Model Evaluation Metrics:\")\n",
        "display(eval_df_retrained)\n",
        "\n",
        "print(\"\\nRetrained Model Confusion Matrix (Threshold = 0.5):\")\n",
        "display(cm_df_retrained)\n",
        "\n",
        "print(\"\\nBaseline Model Evaluation Metrics:\")\n",
        "display(eval_df)\n",
        "\n",
        "print(\"\\nBaseline Model Confusion Matrix (Threshold = 0.5):\")\n",
        "display(cm_df)"
      ],
      "id": "XnHAtR6o1e8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff0aeb9b"
      },
      "source": [
        "## Refine features and model\n",
        "\n",
        "### Subtask:\n",
        "Refine the features or explore different modeling techniques if necessary, based on the evaluation results.\n"
      ],
      "id": "ff0aeb9b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d5de363"
      },
      "source": [
        "**Reasoning**:\n",
        "Based on the lack of improvement with the new features and the limitations of a simple logistic regression model for this problem, I will explore a different model type available in BigQuery ML, specifically a boosted tree classifier, which is often more effective for complex classification tasks.\n",
        "\n"
      ],
      "id": "9d5de363"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57aefd8b"
      },
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET}.churn_boosted_tree_lite`\n",
        "OPTIONS (\n",
        "  model_type = 'BOOSTED_TREE_CLASSIFIER',\n",
        "  input_label_cols = ['churn_next_month'],\n",
        "  data_split_method = 'SEQ',\n",
        "  data_split_col = 'month'\n",
        ") AS\n",
        "SELECT\n",
        "  churn_next_month,\n",
        "  r3_sess,\n",
        "  r3_min,\n",
        "  unique_days_watched,\n",
        "  avg_watch_duration,\n",
        "  days_since_last_month_start,\n",
        "  subscription_plan,\n",
        "  country,\n",
        "  age,\n",
        "  month\n",
        "FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`\n",
        "ORDER BY month;\n",
        "\"\"\"\n",
        "bq.query(sql).result()\n",
        "print(\"‚úì trained boosted tree model:\", f\"{PROJECT_ID}.{DATASET}.churn_boosted_tree_lite\")"
      ],
      "id": "57aefd8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8fbb885"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the boosted tree model is trained, I need to evaluate its performance using ML.EVALUATE, ML.ROC_CURVE, and ML.CONFUSION_MATRIX and store the results for comparison with the previous models.\n",
        "\n"
      ],
      "id": "f8fbb885"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5a13bfa"
      },
      "source": [
        "eval_df_new_model = bq.query(\n",
        "    f\"SELECT * FROM ML.EVALUATE(MODEL `{PROJECT_ID}.{DATASET}.churn_boosted_tree_lite`);\"\n",
        ").result().to_dataframe()\n",
        "\n",
        "roc_df_new_model = bq.query(\n",
        "    f\"SELECT * FROM ML.ROC_CURVE(MODEL `{PROJECT_ID}.{DATASET}.churn_boosted_tree_lite`);\"\n",
        ").result().to_dataframe()\n",
        "\n",
        "cm_df_new_model = bq.query(f\"\"\"\n",
        "SELECT *\n",
        "FROM ML.CONFUSION_MATRIX(\n",
        "  MODEL `{PROJECT_ID}.{DATASET}.churn_boosted_tree_lite`,\n",
        "  (SELECT\n",
        "     churn_next_month,\n",
        "     r3_sess, r3_min, unique_days_watched, avg_watch_duration, days_since_last_month_start,\n",
        "     subscription_plan, country, age\n",
        "   FROM `{PROJECT_ID}.{DATASET}.feat_churn_lite`),\n",
        "  STRUCT(0.5 AS threshold)\n",
        ");\n",
        "\"\"\").result().to_dataframe()\n",
        "\n",
        "print(\"New Boosted Tree Model Evaluation Metrics:\")\n",
        "display(eval_df_new_model)\n",
        "\n",
        "print(\"\\nNew Boosted Tree Model Confusion Matrix (Threshold = 0.5):\")\n",
        "display(cm_df_new_model)\n",
        "\n",
        "print(\"\\nRetrained Logistic Regression Model Evaluation Metrics:\")\n",
        "display(eval_df_retrained)\n",
        "\n",
        "print(\"\\nRetrained Logistic Regression Model Confusion Matrix (Threshold = 0.5):\")\n",
        "display(cm_df_retrained)\n",
        "\n",
        "print(\"\\nBaseline Logistic Regression Model Evaluation Metrics:\")\n",
        "display(eval_df)\n",
        "\n",
        "print(\"\\nBaseline Logistic Regression Model Confusion Matrix (Threshold = 0.5):\")\n",
        "display(cm_df)"
      ],
      "id": "a5a13bfa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ef93603"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial logistic regression model trained with existing features (`r3_sess`, `r3_min`, `subscription_plan`, `country`, `age`) showed poor performance, with an AUC of approximately 0.50 and a high log loss of 0.64. The model predicted the majority class (not churn) for all instances at a 0.5 threshold.\n",
        "*   New features were engineered from the `watch_history` and `users` tables, including `unique_days_watched`, `avg_watch_duration`, and `days_since_last_month_start`.\n",
        "*   Retraining the logistic regression model with these new features did not improve its performance. The evaluation metrics and confusion matrix remained identical to the baseline model, still predicting the majority class for all instances at a 0.5 threshold.\n",
        "*   Exploring a different model type, a boosted tree classifier was trained with the same feature set. This model also did not show significant improvement in overall performance metrics (AUC approximately 0.49, log loss approximately 0.65) compared to the logistic regression models.\n",
        "*   At a 0.5 threshold, the boosted tree model did predict a small number of churn instances correctly (30 True Positives) but also had a very high number of false positives (161144), indicating a strong bias towards predicting the majority class despite some ability to identify minority class instances.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The current set of features, even with the additions from `watch_history`, may not be sufficiently discriminative to capture the complex patterns leading to churn. Further feature engineering focusing on more sophisticated behavioral metrics (e.g., content diversity, engagement recency weighted by time, specific event triggers) is needed.\n",
        "*   Investigating other BigQuery ML models or exploring hyperparameter tuning for the boosted tree model could potentially yield better results, although the feature set appears to be the primary limitation based on current performance.\n"
      ],
      "id": "0ef93603"
    }
  ]
}